{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3b49d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449432/3451848356.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pickle\n",
    "import ramanspy as rp\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "import json\n",
    "BASE_URL = \"https://api.ramanbase.org\"\n",
    "\n",
    "class RamanbaseAPIN:\n",
    "    def __init__(self, api_token: str):\n",
    "        self.token = api_token.strip()\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            \"Authorization\": f\"Token {self.token}\",\n",
    "            \"Accept\": \"application/json\"\n",
    "        })\n",
    "\n",
    "        print(\"initted\")\n",
    "    def fetch_and_save_available_spectra(self, output_dir: str = \".\"):\n",
    "        \"\"\"Fetch available public spectra index (up to API limit) and save it.\"\"\"\n",
    "        url = f\"{BASE_URL}/api/v1/public/spectra/list\"\n",
    "        page_size = 100\n",
    "        all_spectra: List[Dict] = []\n",
    "        page = 1\n",
    "        max_pages = 1400  # Safety cap to avoid infinite loop if bug\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        full_path = os.path.join(output_dir, \"ramanbase_available_spectra_full.json\")\n",
    "        simple_path = os.path.join(output_dir, \"ramanbase_spectra_id_name.json\")\n",
    "        #print('running here')\n",
    "        while page <= max_pages:\n",
    "            print(f'run page {page}')\n",
    "            params = {\"page\": page, \"page_size\": page_size}\n",
    "            try:\n",
    "                response = self.session.get(url, params=params)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                print(f\"Error on page {page}: {e} (likely API limit reached)\")\n",
    "                break\n",
    "\n",
    "            results = data.get(\"results\", [])\n",
    "            if not results:\n",
    "                print(f\"Page {page}: Empty results. API limit reached.\")\n",
    "                break\n",
    "\n",
    "            all_spectra.extend(results)\n",
    "            with open(full_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(all_spectra, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"Page {page}: Fetched {len(results)} spectra (cumulative: {len(all_spectra)})\")\n",
    "\n",
    "            page += 1\n",
    "            time.sleep(1)  # Delay\n",
    "\n",
    "        print(f\"\\nFetching complete! Total spectra downloaded: {len(all_spectra)}\")\n",
    "        print(\"Note: If only 100, that's the current API limit for public list access.\")\n",
    "\n",
    "        # Save full data\n",
    "        with open(full_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(all_spectra, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Full details saved to: {full_path}\")\n",
    "\n",
    "        # Save simple ID/Name list\n",
    "        simple_list = [\n",
    "            {\n",
    "                \"id\": spec[\"id\"],\n",
    "                \"name\": spec.get(\"name\") or \"Unnamed\",\n",
    "                \"identifier\": spec.get(\"identifier\", \"N/A\")\n",
    "            }\n",
    "            for spec in all_spectra\n",
    "        ]\n",
    "        with open(simple_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(simple_list, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Simple ID/Name list saved to: {simple_path}\")\n",
    "\n",
    "        return all_spectra\n",
    "\n",
    "    def get_processed_data(self, spectrum_id: int) -> Dict:\n",
    "        url = f\"{BASE_URL}/api/v1/public/spectra/{spectrum_id}/download/processed\"\n",
    "        response = self.session.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def download_raw_file(self, spectrum_id: int, save_path: Optional[str] = None):\n",
    "        url = f\"{BASE_URL}/api/v1/public/spectra/{spectrum_id}/download/raw\"\n",
    "        response = self.session.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if save_path is None:\n",
    "            disposition = response.headers.get('Content-Disposition', '')\n",
    "            filename = disposition.split('filename=')[-1].strip('\"') if 'filename=' in disposition else f\"spectrum_{spectrum_id}_raw\"\n",
    "            save_path = filename\n",
    "\n",
    "        os.makedirs(os.path.dirname(save_path) or '.', exist_ok=True)\n",
    "        with open(save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Raw file saved to {save_path}\")\n",
    "\n",
    "json_path = Path(\"ramanbase_available_spectra_full.json\") #RamanBase index (in the repository)\n",
    "\n",
    "with json_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    spectra_index = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa14a04f",
   "metadata": {},
   "source": [
    "# Dataset assembly based on RamanBase resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458dac74",
   "metadata": {},
   "source": [
    "# 1. Selecting the spectra of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ddfce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example querywords for dataset assembly\n",
    "querywords = [\n",
    "    # --- solvents & small organics ---\n",
    "    \"water\",\n",
    "    \"methanol\",\n",
    "    \"ethanol\",\n",
    "    \"isopropanol\",\n",
    "    \"isopropyl alcohol\",\n",
    "    \"propanol\",\n",
    "    \"butanol\",\n",
    "    \"glycerol\",\n",
    "    \"ethylene glycol\",\n",
    "    \"acetone\",\n",
    "    \"methyl ethyl ketone\",\n",
    "    \"acetonitrile\",\n",
    "    \"dimethyl sulfoxide\",\n",
    "    \"DMSO\",\n",
    "    \"dimethylformamide\",\n",
    "    \"DMF\",\n",
    "    \"tetrahydrofuran\",\n",
    "    \"THF\",\n",
    "    \"diethyl ether\",\n",
    "    \"dioxane\",\n",
    "    \"chloroform\",\n",
    "    \"dichloromethane\",\n",
    "    \"carbon tetrachloride\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f00956c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1155 dataset entries\n"
     ]
    }
   ],
   "source": [
    "index_fordset=[]\n",
    "names=[]\n",
    "for dict in spectra_index:\n",
    "    for word in querywords:\n",
    "        try:\n",
    "            if word in dict['name'].lower():\n",
    "                index_fordset.append(dict)\n",
    "                names.append(dict['name'])\n",
    "        except:\n",
    "            pass\n",
    "print(f'Found {len(index_fordset)} dataset entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc5a63",
   "metadata": {},
   "source": [
    "# 2. Fetching and saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa79e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initted\n"
     ]
    }
   ],
   "source": [
    "tok=\"\" #your RamanBase API (https://ramanbase.org/) token\n",
    "api = RamanbaseAPIN(api_token=tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97714c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "dsetpath='ramanbaseprocspec_ex.json'\n",
    "all_spectra = []\n",
    "ind=0\n",
    "start=False\n",
    "for spec in tqdm(index_fordset):\n",
    "    specid=spec['id']\n",
    "    specname=spec['name']\n",
    "    specidentifier=spec['identifier']\n",
    "    url=spec['url']\n",
    "    try:\n",
    "        res=api.get_processed_data(specid)\n",
    "        res['id']=specid\n",
    "        res['identifier']=specidentifier\n",
    "        res['name']=specname\n",
    "        res['url']=url\n",
    "        res['series']=spec['series']\n",
    "        res['spectroscopy_type']=spec['spectroscopy_type']\n",
    "        all_spectra.append(res)\n",
    "        time.sleep(1)\n",
    "        ind+=1\n",
    "        if ind%100==0:\n",
    "            with open(dsetpath, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(all_spectra, f, indent=2, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d0d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8649a9857175408683cb1aface1a1579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "json_path = Path(\"ramanbaseprocspec_ex.json\")\n",
    "\n",
    "with json_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    rbase = json.load(f)\n",
    "\n",
    "rbase_specdict={}\n",
    "for spec in tqdm(rbase):\n",
    "    try:\n",
    "        specax=spec['x']\n",
    "        specint=spec['y']\n",
    "        id=spec['id']\n",
    "        name=spec['name']\n",
    "        url=spec['url']\n",
    "        spectrum=rp.Spectrum(np.array(specint[0]), np.array(specax))\n",
    "\n",
    "        rbase_specdict[id]={'spectrum':spectrum,\n",
    "                            'name':name,\n",
    "                            'url':url,\n",
    "                            'identifier':spec['identifier']}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "with open(\"rbase_specdictcur.pkl\", \"wb\") as f: #this file is used by the app\n",
    "    pickle.dump(rbase_specdict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a526a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rbase_specdictcur.pkl\", \"rb\") as f:\n",
    "    specdict=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "116f4950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'spectrum': <ramanspy.core.Spectrum at 0x7cd1c9e7d210>,\n",
       "  'name': 'Dimethyl sulfoxide-d6 CAS 2206-27-1',\n",
       "  'url': None,\n",
       "  'identifier': 'EsO7C3'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw='sulfoxide'\n",
    "[specdict[i] for i  in list(specdict.keys()) if sw in specdict[i]['name'].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc78996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
